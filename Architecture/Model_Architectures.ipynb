{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUcLcj3Y-rpo"
   },
   "source": [
    "## **Hemorrhage Classifier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ay1o4mzuYrV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /home/addy/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n",
      "51.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "60.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "70.2%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "79.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "88.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "97.5%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "alexnet_model = torchvision.models.alexnet(pretrained=True)\n",
    "alexnet_model.features[0] = nn.Conv2d(1, 64, kernel_size= 7, stride= 2, padding= 3)\n",
    "\n",
    "class HemorrhageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HemorrhageClassifier, self).__init__()\n",
    "        self.name = \"Classifier\"\n",
    "\n",
    "        for param in alexnet_model.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 512 * 1, 100)\n",
    "        self.fc2 = nn.Linear(100, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = alexnet_model.features(x)\n",
    "        x = x.view(-1, 512 * 512 * 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAMPFBo6mn12"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "resnet152 = torchvision.models.resnet152(pretrained=True)\n",
    "modules = list(resnet152.children())\n",
    "modules[0].in_channels = 1\n",
    "\n",
    "class HemorrhageClassifier2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HemorrhageClassifier2, self).__init__()\n",
    "        self.name = \"Classifier 2\"\n",
    "\n",
    "        for param in resnet152.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 512 * 1, 100)\n",
    "        self.fc2 = nn.Linear(100, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = resnet152(x)\n",
    "        x = x.view(-1, 512 * 512 * 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HX23rHLw-zvs"
   },
   "source": [
    "## **Hemorrhage Detector**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wYexXEgE6P3"
   },
   "source": [
    "**Two convulational layers:**\n",
    "  - each have a 5x5 receptive field, 2x2 stride, and 2x2 padding\n",
    "\n",
    "**The number of feature maps:**\n",
    "  - for the 1st convulational layer is 10\n",
    "  - for the 2nd convolutional layer is 20\n",
    "\n",
    "**Two Pooling Layers:**\n",
    "  - Receptive field: 2x2, stride: 2x2\n",
    "\n",
    "**Fully Connected layer:**\n",
    "  - 100 nodes\n",
    "  - 2 output nodes (binary classification)\n",
    "\n",
    "**Training Parameters:**\n",
    "\n",
    "lr = 0.02\n",
    "momentum =0.01\n",
    "4000 iterations (60 epochs)\n",
    "Batch size of 20\n",
    "Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "GAEyk5RdXvo-",
    "outputId": "31bc541f-7d92-4d06-9581-d4099b1c9a6b"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "alexnet_model = torchvision.models.alexnet(pretrained=True)\n",
    "alexnet_model.features[0] = nn.Conv2d(1, 64, kernel_size= 7, stride= 2, padding= 3)\n",
    "\n",
    "class HemorrhageDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HemorrhageDetector, self).__init__()\n",
    "        self.name = \"Detector\"\n",
    "\n",
    "        for param in alexnet_model.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 512 * 1, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = alexnet_model.features(x)\n",
    "        x = x.view(-1, 512 * 512 * 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBkK6sUWiDj4"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "resnet152 = torchvision.models.resnet152(pretrained=True)\n",
    "modules = list(resnet152.children())\n",
    "modules[0].in_channels = 1\n",
    "\n",
    "class HemorrhageDetector2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HemorrhageDetector2, self).__init__()\n",
    "        self.name = \"Detector 2\"\n",
    "\n",
    "        for param in resnet152.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 512 * 1, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = resnet152(x)\n",
    "        x = x.view(-1, 512 * 512 * 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "163ShF1WqWEw"
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NjV2sU8qqVd0"
   },
   "outputs": [],
   "source": [
    "def train(model, dataset, batch_size = 64, learning_rate=0.01, num_epochs=30):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "    \n",
    "    training_loader = torch.utils.data.DataLoader(dataset, batch_size= batch_size)\n",
    "\n",
    "    n = 0 \n",
    "    for epoch in range(num_epochs):\n",
    "        count = 0\n",
    "        for imgs, labels in iter(training_loader):\n",
    "            imgs = features = torch.load(f'training_features_batchcount{count}.tensor')\n",
    "            imgs = torch.from_numpy(imgs.detach().numpy())\n",
    "\n",
    "            #To Enable GPU Usage\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "              imgs = imgs.cuda()\n",
    "              labels = labels.cuda()\n",
    "            #############################################\n",
    "            \n",
    "            outputs = model(imgs)             \n",
    "            loss = criterion(outputs, labels) \n",
    "            loss.backward()               \n",
    "            optimizer.step()              \n",
    "            optimizer.zero_grad()         \n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # finding the average loss\n",
    "            train_acc.append(get_alex_accuracy(model, train=True)) # finding the training accuracy \n",
    "            val_acc.append(get_alex_accuracy(model, train=False))  # finding the validation accuracy\n",
    "            n = n+1\n",
    "            count = count+1\n",
    "        print(\"Epoch: \",epoch,\". Training Accuracy: \", train_acc[n-1],\". Validation Accuracy: \",val_acc[n-1])\n",
    "\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training vs. Validation Accuracy Curves\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN Architecture.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
