{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUcLcj3Y-rpo"
   },
   "source": [
    "## **Hemorrhage Classifier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ay1o4mzuYrV"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "model.features[0] = nn.Conv2d(1, 64, kernel_size= 7, stride= 2, padding= 3)\n",
    "\n",
    "class HemorrhageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HemorrhageClassifier, self).__init__()\n",
    "        self.name = \"Classifier\"\n",
    "\n",
    "        for param in model.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 512 * 1, 100)\n",
    "        self.fc2 = nn.Linear(100, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = alexnet.features(x)\n",
    "        x = x.view(-1, 512 * 512 * 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAMPFBo6mn12"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "model = torchvision.models.resnet152(pretrained=True)\n",
    "\n",
    "class HemorrhageClassifier2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HemorrhageClassifier2, self).__init__()\n",
    "        self.name = \"Classifier 2\"\n",
    "\n",
    "        modules = list(model.children())[:-1]\n",
    "        model = nn.Sequential(*modules)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 512 * 1, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = alexnet.features(x)\n",
    "        x = x.view(-1, 512 * 512 * 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HX23rHLw-zvs"
   },
   "source": [
    "## **Hemorrhage Detector**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wYexXEgE6P3"
   },
   "source": [
    "**Two convulational layers:**\n",
    "  - each have a 5x5 receptive field, 2x2 stride, and 2x2 padding\n",
    "\n",
    "**The number of feature maps:**\n",
    "  - for the 1st convulational layer is 10\n",
    "  - for the 2nd convolutional layer is 20\n",
    "\n",
    "**Two Pooling Layers:**\n",
    "  - Receptive field: 2x2, stride: 2x2\n",
    "\n",
    "**Fully Connected layer:**\n",
    "  - 100 nodes\n",
    "  - 2 output nodes (binary classification)\n",
    "\n",
    "**Training Parameters:**\n",
    "\n",
    "lr = 0.02\n",
    "momentum =0.01\n",
    "4000 iterations (60 epochs)\n",
    "Batch size of 20\n",
    "Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "GAEyk5RdXvo-",
    "outputId": "31bc541f-7d92-4d06-9581-d4099b1c9a6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n",
      "100%|██████████| 233M/233M [00:03<00:00, 69.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "model.features[0] = nn.Conv2d(1, 64, kernel_size= 7, stride= 2, padding= 3)\n",
    "\n",
    "class HemorrhageDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HemorrhageDetector, self).__init__()\n",
    "        self.name = \"Detector\"\n",
    "\n",
    "        for param in model.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 512 * 1, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = alexnet.features(x)\n",
    "        x = x.view(-1, 512 * 512 * 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBkK6sUWiDj4"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "\n",
    "model = torchvision.models.resnet152(pretrained=True)\n",
    "\n",
    "class HemorrhageDetector2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HemorrhageDetector2, self).__init__()\n",
    "        self.name = \"Detector 2\"\n",
    "\n",
    "        modules = list(model.children())[:-1]\n",
    "        model = nn.Sequential(*modules)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 512 * 1, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = alexnet.features(x)\n",
    "        x = x.view(-1, 512 * 512 * 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "163ShF1WqWEw"
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NjV2sU8qqVd0"
   },
   "outputs": [],
   "source": [
    "def train(model, dataset, batch_size = 64, learning_rate=0.01, num_epochs=30):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "    \n",
    "    training_loader = torch.utils.data.DataLoader(dataset, batch_size= batch_size)\n",
    "\n",
    "    n = 0 \n",
    "    for epoch in range(num_epochs):\n",
    "        count = 0\n",
    "        for imgs, labels in iter(training_loader):\n",
    "            imgs = features = torch.load(f'training_features_batchcount{count}.tensor')\n",
    "            imgs = torch.from_numpy(imgs.detach().numpy())\n",
    "\n",
    "            #To Enable GPU Usage\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "              imgs = imgs.cuda()\n",
    "              labels = labels.cuda()\n",
    "            #############################################\n",
    "            \n",
    "            outputs = model(imgs)             \n",
    "            loss = criterion(outputs, labels) \n",
    "            loss.backward()               \n",
    "            optimizer.step()              \n",
    "            optimizer.zero_grad()         \n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # finding the average loss\n",
    "            train_acc.append(get_alex_accuracy(model, train=True)) # finding the training accuracy \n",
    "            val_acc.append(get_alex_accuracy(model, train=False))  # finding the validation accuracy\n",
    "            n = n+1\n",
    "            count = count+1\n",
    "        print(\"Epoch: \",epoch,\". Training Accuracy: \", train_acc[n-1],\". Validation Accuracy: \",val_acc[n-1])\n",
    "\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training vs. Validation Accuracy Curves\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN Architecture.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
