{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(r'../Data/')\n",
    "from dataloader import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLosses(model_save_path):\n",
    "    \n",
    "    # Find csv\n",
    "    files = os.listdir(model_save_path)\n",
    "    csv_file = [file for file in files if \".csv\" in file][0] \n",
    "    loss = pd.read_csv(os.path.join(model_save_path, csv_file))\n",
    "    \n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.plot(loss, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longestSubstringFinder(string1, string2):\n",
    "    answer = \"\"\n",
    "    len1, len2 = len(string1), len(string2)\n",
    "    for i in range(len1):\n",
    "        match = \"\"\n",
    "        for j in range(len2):\n",
    "            if (i + j < len1 and string1[i + j] == string2[j]):\n",
    "                match += string2[j]\n",
    "            else:\n",
    "                if (len(match) > len(answer)): answer = match\n",
    "                match = \"\"\n",
    "    return answer\n",
    "\n",
    "def getUniqueBtwStrings(strings):\n",
    "    \n",
    "    common_factor = longestSubstringFinder(strings[0], strings[1])\n",
    "    unique = []\n",
    "    for string in strings:\n",
    "        r = string.replace(common_factor, \"\").replace(\"_epoch\", \"\")\n",
    "        unique.append(r)\n",
    "    return unique\n",
    "\n",
    "def findBs(string):\n",
    "    end_idx = string.find(\"_bs\")\n",
    "    return string[:end_idx]\n",
    "\n",
    "def getAccuracy(model, data_loader, use_cuda):\n",
    "\n",
    "    cor = 0\n",
    "    total = 0\n",
    "    n = 0\n",
    "    for imgs, labels in data_loader:\n",
    "        imgs = torch.from_numpy(imgs.detach().numpy())\n",
    "        #To Enable GPU Usage\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        #############################################\n",
    "        output = model(imgs)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        cor = cor + pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total = total + imgs.shape[0]\n",
    "        n = n+1\n",
    "    return cor / total\n",
    "\n",
    "def plotAccuracy(model_class, model_save_path, val_dataset, train_dataset = None, use_cuda = False):\n",
    "    \n",
    "    model_dicts = [file for file in os.listdir(model_save_path) if \".csv\" not in file]\n",
    "    if train_dataset:\n",
    "        t_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=findBs(model_dicts[0]))\n",
    "    v_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "    epochs, t_accs, v_accs = getUniqueBtwStrings(model_dicts), [], []\n",
    "    i = 0\n",
    "    \n",
    "    # for each model dict, create model\n",
    "    for model_params in model_dicts:\n",
    "        print(i)\n",
    "        # load model\n",
    "        model = model_class()\n",
    "        checkpoint = torch.load(os.path.join(model_save_path, model_params))\n",
    "        model.load_state_dict(checkpoint)\n",
    "        # get acc for model and append\n",
    "        if train_dataset:\n",
    "            t_accs.append(getAccuracy(model, t_data_loader, use_cuda))\n",
    "        v_accs.append(getAccuracy(model, v_data_loader, use_cuda))\n",
    "        i+=1\n",
    "    \n",
    "    # Plot    \n",
    "    plt.title(\"Training vs. Validation Accuracy Curves\")\n",
    "    if train_dataset:\n",
    "        plt.plot(epochs, t_accs, label=\"Train\")\n",
    "    plt.plot(epochs, v_accs, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotLosses(\"Model_Overfit_detector_Alex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking epidural\n",
      "Unpacking intraparenchymal\n",
      "Unpacking subarachnoid\n",
      "Unpacking intraventricular\n",
      "Unpacking subdural\n",
      "Unpacking nohem\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "val_folders = [\n",
    "    \"../Data/Processed/val/epidural\",\n",
    "    \"../Data/Processed/val/intraparenchymal\",\n",
    "    \"../Data/Processed/val/subarachnoid\",\n",
    "    \"../Data/Processed/val/intraventricular\",\n",
    "    \"../Data/Processed/val/subdural\",\n",
    "    \"../Data/Processed/val/nohem\",\n",
    "]\n",
    "\n",
    "val_data = Data(val_folders, {\n",
    "    \"epidural\":\"any\", \n",
    "    \"intraparenchymal\":\"any\", \n",
    "    \"subarachnoid\":\"any\", \n",
    "    \"intraventricular\":\"any\", \n",
    "    \"subdural\":\"any\", \n",
    "}, 10)\n",
    "\n",
    "# from Full_detector_training import HemorrhageDetector\n",
    "\n",
    "alexnet_model = torchvision.models.alexnet(pretrained=True)\n",
    "alexnet_model.features[0] = nn.Conv2d(1, 64, kernel_size= 7, stride= 2, padding= 3)\n",
    "\n",
    "class HemorrhageDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HemorrhageDetector, self).__init__()\n",
    "        self.name = \"Detector\"\n",
    "\n",
    "        for param in alexnet_model.parameters():\n",
    "              param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(256*31*31, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = alexnet_model.features(x)\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, 256*31*31)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "plotAccuracy(HemorrhageDetector, \"Model_Overfit_detector_Alex\", val_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
